2023-02-17 11:12:30,095 - INFO - 
Config:
'add_train': False
'batch_size': 16
'cudadevice': 'cuda:1'
'cur_time': '2023_02_17_11_12_29'
'data_selected': ['A1']
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': False
'do_predict_roll': False
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'dynamic_data_root': 'input/csv/dynamic'
'dynamic_length': 2
'embedding_size': 256
'epoch': 100
'feature_columns': [0, 1, 3]
'figure_save_path': 'result/figure/'
'hidden_size': 256
'humansize': 9
'input_size': 3
'label_columns': [3]
'label_in_feature_index': [2]
'learning_rate': 5e-05
'log_save_path': 'result/logs/2023_02_17_11_12_29_pytorch/'
'lstm_layers': 2
'model_name': '.pth'
'model_postfix': {'pytorch': '.pth'}
'model_save_path': 'result/model/'
'name': 'A1_Attention_hc_True_changeDe_RMLSE16_dynamic_only53'
'naturesize': 4
'only_dynamic': 1
'only_static_concat_dynamic': 0
'only_static_plus_dynamic': 0
'output_size': 1
'patience': 5
'predict_day': 3
'random_seed': 42
'roll_predict_day': 125
'shuffle_train_data': False
'static_data_path': 'input/csv/static/All_static.csv'
'static_human_column': [4, 5, 6, 7, 8, 9, 10, 11, 12]
'static_nature_column': [0, 1, 2, 3]
'time_step': 5
'train_data_rate': 0.95
'train_name': 'A1'
'traindata': 'traindata'
'ttotrain': 1
'use_attention': True
'use_cuda': True
'use_static_embedding': True
'used_frame': 'pytorch'
'val_name': 'C1'
'valid_data_rate': 0.15
2023-02-17 11:12:32,656 - INFO - Epoch 0/100
2023-02-17 11:12:35,917 - INFO - The train loss is 0.863690. The valid loss is 1.156129.
2023-02-17 11:12:35,937 - INFO - Epoch 1/100
2023-02-17 11:12:36,716 - INFO - The train loss is 0.638804. The valid loss is 0.570664.
2023-02-17 11:12:36,739 - INFO - Epoch 2/100
2023-02-17 11:12:37,503 - INFO - The train loss is 0.379422. The valid loss is 0.362885.
2023-02-17 11:12:37,525 - INFO - Epoch 3/100
2023-02-17 11:12:38,288 - INFO - The train loss is 0.331212. The valid loss is 0.479900.
2023-02-17 11:12:38,288 - INFO - Epoch 4/100
2023-02-17 11:12:39,045 - INFO - The train loss is 0.355407. The valid loss is 0.676063.
2023-02-17 11:12:39,045 - INFO - Epoch 5/100
2023-02-17 11:12:39,810 - INFO - The train loss is 0.436152. The valid loss is 0.414764.
2023-02-17 11:12:39,810 - INFO - Epoch 6/100
2023-02-17 11:12:40,566 - INFO - The train loss is 0.293898. The valid loss is 0.287701.
2023-02-17 11:12:40,588 - INFO - Epoch 7/100
2023-02-17 11:12:41,364 - INFO - The train loss is 0.268179. The valid loss is 0.258838.
2023-02-17 11:12:41,403 - INFO - Epoch 8/100
2023-02-17 11:12:42,171 - INFO - The train loss is 0.257533. The valid loss is 0.293512.
2023-02-17 11:12:42,171 - INFO - Epoch 9/100
2023-02-17 11:12:42,926 - INFO - The train loss is 0.237897. The valid loss is 0.242228.
2023-02-17 11:12:42,948 - INFO - Epoch 10/100
2023-02-17 11:12:43,720 - INFO - The train loss is 0.237343. The valid loss is 0.271024.
2023-02-17 11:12:43,720 - INFO - Epoch 11/100
2023-02-17 11:12:44,497 - INFO - The train loss is 0.519728. The valid loss is 1.588092.
2023-02-17 11:12:44,497 - INFO - Epoch 12/100
2023-02-17 11:12:45,244 - INFO - The train loss is 1.472990. The valid loss is 1.903259.
2023-02-17 11:12:45,244 - INFO - Epoch 13/100
2023-02-17 11:12:46,012 - INFO - The train loss is 1.318445. The valid loss is 1.619451.
2023-02-17 11:12:46,012 - INFO - Epoch 14/100
2023-02-17 11:12:46,775 - INFO - The train loss is 1.212184. The valid loss is 1.578243.
2023-02-17 11:12:46,775 - INFO -  The training stops early in epoch 14
