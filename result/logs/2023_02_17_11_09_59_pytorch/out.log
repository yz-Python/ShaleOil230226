2023-02-17 11:10:00,322 - INFO - 
Config:
'add_train': False
'batch_size': 16
'cudadevice': 'cuda:1'
'cur_time': '2023_02_17_11_09_59'
'data_selected': ['A1']
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': False
'do_predict_roll': False
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'dynamic_data_root': 'input/csv/dynamic'
'dynamic_length': 2
'embedding_size': 256
'epoch': 100
'feature_columns': [0, 1, 3]
'figure_save_path': 'result/figure/'
'hidden_size': 256
'humansize': 9
'input_size': 3
'label_columns': [3]
'label_in_feature_index': [2]
'learning_rate': 5e-05
'log_save_path': 'result/logs/2023_02_17_11_09_59_pytorch/'
'lstm_layers': 2
'model_name': '.pth'
'model_postfix': {'pytorch': '.pth'}
'model_save_path': 'result/model/'
'name': 'A1_No_Attention_hc_False_changeDe_RMLSE16_ds_fusion53'
'naturesize': 4
'only_dynamic': 0
'only_static_concat_dynamic': 0
'only_static_plus_dynamic': 0
'output_size': 1
'patience': 5
'predict_day': 3
'random_seed': 42
'roll_predict_day': 125
'shuffle_train_data': False
'static_data_path': 'input/csv/static/All_static.csv'
'static_human_column': [4, 5, 6, 7, 8, 9, 10, 11, 12]
'static_nature_column': [0, 1, 2, 3]
'time_step': 5
'train_data_rate': 0.95
'train_name': 'A1'
'traindata': 'traindata'
'ttotrain': 1
'use_attention': False
'use_cuda': True
'use_static_embedding': False
'used_frame': 'pytorch'
'val_name': 'C1'
'valid_data_rate': 0.15
2023-02-17 11:10:02,861 - INFO - Epoch 0/100
2023-02-17 11:10:10,248 - INFO - The train loss is 0.814921. The valid loss is 1.056229.
2023-02-17 11:10:10,265 - INFO - Epoch 1/100
2023-02-17 11:10:15,173 - INFO - The train loss is 0.568060. The valid loss is 0.496334.
2023-02-17 11:10:15,189 - INFO - Epoch 2/100
2023-02-17 11:10:20,258 - INFO - The train loss is 0.451972. The valid loss is 0.623082.
2023-02-17 11:10:20,258 - INFO - Epoch 3/100
2023-02-17 11:10:25,463 - INFO - The train loss is 0.490105. The valid loss is 0.859550.
2023-02-17 11:10:25,463 - INFO - Epoch 4/100
2023-02-17 11:10:30,607 - INFO - The train loss is 0.419085. The valid loss is 0.438631.
2023-02-17 11:10:30,628 - INFO - Epoch 5/100
2023-02-17 11:10:34,975 - INFO - The train loss is 0.315266. The valid loss is 0.333058.
2023-02-17 11:10:34,992 - INFO - Epoch 6/100
2023-02-17 11:10:39,059 - INFO - The train loss is 0.285749. The valid loss is 0.272234.
2023-02-17 11:10:39,075 - INFO - Epoch 7/100
2023-02-17 11:10:43,144 - INFO - The train loss is 0.271215. The valid loss is 0.239788.
2023-02-17 11:10:43,161 - INFO - Epoch 8/100
2023-02-17 11:10:47,212 - INFO - The train loss is 0.258301. The valid loss is 0.232002.
2023-02-17 11:10:47,229 - INFO - Epoch 9/100
2023-02-17 11:10:51,278 - INFO - The train loss is 0.245114. The valid loss is 0.218041.
2023-02-17 11:10:51,295 - INFO - Epoch 10/100
2023-02-17 11:10:55,352 - INFO - The train loss is 0.237134. The valid loss is 0.248728.
2023-02-17 11:10:55,352 - INFO - Epoch 11/100
2023-02-17 11:10:59,436 - INFO - The train loss is 0.245567. The valid loss is 0.250141.
2023-02-17 11:10:59,437 - INFO - Epoch 12/100
2023-02-17 11:11:03,497 - INFO - The train loss is 0.317136. The valid loss is 0.781697.
2023-02-17 11:11:03,498 - INFO - Epoch 13/100
2023-02-17 11:11:07,603 - INFO - The train loss is 0.495216. The valid loss is 0.682678.
2023-02-17 11:11:07,603 - INFO - Epoch 14/100
2023-02-17 11:11:11,658 - INFO - The train loss is 0.464618. The valid loss is 0.611196.
2023-02-17 11:11:11,659 - INFO -  The training stops early in epoch 14
