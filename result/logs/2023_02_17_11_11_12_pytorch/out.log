2023-02-17 11:11:13,386 - INFO - 
Config:
'add_train': False
'batch_size': 16
'cudadevice': 'cuda:1'
'cur_time': '2023_02_17_11_11_12'
'data_selected': ['A1']
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': False
'do_predict_roll': False
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'dynamic_data_root': 'input/csv/dynamic'
'dynamic_length': 2
'embedding_size': 256
'epoch': 100
'feature_columns': [0, 1, 3]
'figure_save_path': 'result/figure/'
'hidden_size': 256
'humansize': 9
'input_size': 3
'label_columns': [3]
'label_in_feature_index': [2]
'learning_rate': 5e-05
'log_save_path': 'result/logs/2023_02_17_11_11_12_pytorch/'
'lstm_layers': 2
'model_name': '.pth'
'model_postfix': {'pytorch': '.pth'}
'model_save_path': 'result/model/'
'name': 'A1_No_Attention_hc_True_changeDe_RMLSE16_dynamic_only53'
'naturesize': 4
'only_dynamic': 1
'only_static_concat_dynamic': 0
'only_static_plus_dynamic': 0
'output_size': 1
'patience': 5
'predict_day': 3
'random_seed': 42
'roll_predict_day': 125
'shuffle_train_data': False
'static_data_path': 'input/csv/static/All_static.csv'
'static_human_column': [4, 5, 6, 7, 8, 9, 10, 11, 12]
'static_nature_column': [0, 1, 2, 3]
'time_step': 5
'train_data_rate': 0.95
'train_name': 'A1'
'traindata': 'traindata'
'ttotrain': 1
'use_attention': False
'use_cuda': True
'use_static_embedding': True
'used_frame': 'pytorch'
'val_name': 'C1'
'valid_data_rate': 0.15
2023-02-17 11:11:16,003 - INFO - Epoch 0/100
2023-02-17 11:11:19,082 - INFO - The train loss is 0.795175. The valid loss is 0.978870.
2023-02-17 11:11:19,097 - INFO - Epoch 1/100
2023-02-17 11:11:19,616 - INFO - The train loss is 0.510714. The valid loss is 0.455282.
2023-02-17 11:11:19,633 - INFO - Epoch 2/100
2023-02-17 11:11:20,138 - INFO - The train loss is 0.418406. The valid loss is 0.452253.
2023-02-17 11:11:20,154 - INFO - Epoch 3/100
2023-02-17 11:11:20,656 - INFO - The train loss is 0.453885. The valid loss is 0.586430.
2023-02-17 11:11:20,656 - INFO - Epoch 4/100
2023-02-17 11:11:21,168 - INFO - The train loss is 0.372212. The valid loss is 0.328514.
2023-02-17 11:11:21,184 - INFO - Epoch 5/100
2023-02-17 11:11:21,702 - INFO - The train loss is 0.427898. The valid loss is 0.688926.
2023-02-17 11:11:21,702 - INFO - Epoch 6/100
2023-02-17 11:11:22,217 - INFO - The train loss is 0.423462. The valid loss is 0.481537.
2023-02-17 11:11:22,217 - INFO - Epoch 7/100
2023-02-17 11:11:22,737 - INFO - The train loss is 0.315282. The valid loss is 0.294939.
2023-02-17 11:11:22,753 - INFO - Epoch 8/100
2023-02-17 11:11:23,272 - INFO - The train loss is 0.279369. The valid loss is 0.260626.
2023-02-17 11:11:23,288 - INFO - Epoch 9/100
2023-02-17 11:11:23,805 - INFO - The train loss is 0.250073. The valid loss is 0.247441.
2023-02-17 11:11:23,861 - INFO - Epoch 10/100
2023-02-17 11:11:24,394 - INFO - The train loss is 0.252216. The valid loss is 0.242067.
2023-02-17 11:11:24,411 - INFO - Epoch 11/100
2023-02-17 11:11:24,917 - INFO - The train loss is 0.248808. The valid loss is 0.280868.
2023-02-17 11:11:24,917 - INFO - Epoch 12/100
2023-02-17 11:11:25,435 - INFO - The train loss is 0.251185. The valid loss is 0.283448.
2023-02-17 11:11:25,435 - INFO - Epoch 13/100
2023-02-17 11:11:25,946 - INFO - The train loss is 0.266974. The valid loss is 0.455523.
2023-02-17 11:11:25,946 - INFO - Epoch 14/100
2023-02-17 11:11:26,460 - INFO - The train loss is 0.294527. The valid loss is 0.245924.
2023-02-17 11:11:26,460 - INFO - Epoch 15/100
2023-02-17 11:11:26,967 - INFO - The train loss is 0.229487. The valid loss is 0.262052.
2023-02-17 11:11:26,968 - INFO -  The training stops early in epoch 15
